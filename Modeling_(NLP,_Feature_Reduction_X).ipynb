{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling (NLP, Feature Reduction X)",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1pnsFLgsuCelfBp5JhJNfLOGoZkn75Egy",
      "authorship_tag": "ABX9TyOomUZ7VAuPYy0TG7TtwlXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjiky7777/MBA-Project/blob/main/Modeling_(NLP%2C_Feature_Reduction_X).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yacoSIVCtOdG",
        "outputId": "5433ff20-c51b-41a7-e769-0e361c8fa96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "from yellowbrick.classifier import ROCAUC\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoVRLhc7xZm5",
        "outputId": "3f31f81c-e347-4226-ccb3-f545e9d39720"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "\n",
        "X =  pd.read_csv('/content/drive/My Drive/finbert/FRED.csv')\n",
        "\n",
        "name = pd.read_csv('/content/drive/My Drive/finbert/FRED_appendix.csv')\n",
        "\n",
        "Y = pd.read_csv('/content/drive/My Drive/finbert/S&P500.csv')"
      ],
      "metadata": {
        "id": "9ZfNJYXLuzBi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DITCbmHaNw2",
        "outputId": "df67402f-56f4-4643-81e8-6b048aa5fa3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(267, 128) (267, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 과정\n",
        "\n",
        "del X['sasdate']\n",
        "\n",
        "Y = Y['Result']\n",
        "\n",
        "X.rename(columns={'IPB51222S':'IPB51222s'},inplace=True)\n",
        "\n",
        "X = X.fillna(0)\n",
        "\n",
        "\n",
        "# 변수 선택\n",
        "\n",
        "feature_name = name['fred']\n",
        "\n",
        "X = X.loc[:,feature_name]\n"
      ],
      "metadata": {
        "id": "m6x62IDD0T9O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "xXhCd3TzDr7W",
        "outputId": "6f9ba684-01fd-44f4-c00d-11830cdc734c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           RPI  W875RX1  DPCERA3M086SBEA  CMRMTSPLx  RETAILx   IPFPNSS  \\\n",
              "0    10861.073   9498.6           76.746    1129614   268044   99.3409   \n",
              "1    10906.015   9541.8           77.468    1109286   272020   99.8416   \n",
              "2    10936.525   9573.1           77.850    1122401   275192  100.0390   \n",
              "3    10996.136   9620.5           77.827    1131729   271046  100.8609   \n",
              "4    11035.828   9628.6           78.118    1125723   271394  101.0331   \n",
              "..         ...      ...              ...        ...      ...       ...   \n",
              "262  17801.835  14463.1          125.640    1572476   644741  101.2536   \n",
              "263  17791.488  14465.3          123.868    1562935   634393  100.8807   \n",
              "264  17711.363  14444.5          125.781    1581814   651557  101.7294   \n",
              "265  17727.726  14485.8          125.878    1570284   662321  102.9275   \n",
              "266  17666.265  14447.6          126.480    1551969   671648  103.6544   \n",
              "\n",
              "      IPFINAL  IPDCONGD  IPNCONGD  IPBUSEQ  ...  DNDGRG3M086SBEA  \\\n",
              "0     96.5258   98.4850  102.5384  83.8829  ...           72.498   \n",
              "1     97.1313   98.1898  103.7785  84.5120  ...           73.025   \n",
              "2     97.2144   97.8025  103.3591  85.6665  ...           73.959   \n",
              "3     98.0194   99.0959  104.0481  86.6401  ...           73.660   \n",
              "4     98.3635   98.7398  104.4840  87.4207  ...           73.531   \n",
              "..        ...       ...       ...      ...  ...              ...   \n",
              "262  101.6843  104.7551   99.6725  95.9763  ...          105.852   \n",
              "263  101.3610  103.9402   99.3044  95.9503  ...          106.351   \n",
              "264  102.2818  105.6880  100.5197  95.5580  ...          107.154   \n",
              "265  103.3749  103.8407  101.8127  97.3472  ...          109.075   \n",
              "266  104.3039  107.3327  101.8590  98.7428  ...          112.130   \n",
              "\n",
              "     DSERRG3M086SBEA  CES0600000008  CES2000000008  CES3000000008  UMCSENTx  \\\n",
              "0             71.832          15.01          17.11          14.13     112.0   \n",
              "1             72.046          15.06          17.20          14.14     111.3   \n",
              "2             72.174          15.10          17.28          14.17     107.1   \n",
              "3             72.207          15.17          17.39          14.23     109.2   \n",
              "4             72.346          15.17          17.38          14.22     110.7   \n",
              "..               ...            ...            ...            ...       ...   \n",
              "262          126.278          26.99          31.04          24.24      67.4   \n",
              "263          126.834          27.17          31.25          24.38      70.6   \n",
              "264          127.248          27.31          31.44          24.51      67.2   \n",
              "265          127.566          27.42          31.60          24.56      62.8   \n",
              "266          128.165          27.50          31.67          24.71      59.4   \n",
              "\n",
              "     DTCOLNVHFNM   DTCTHFNM     INVEST  VIXCLSx  \n",
              "0      132467.09  421056.34  1147.6935  24.8430  \n",
              "1      136610.16  422437.48  1140.6992  25.4560  \n",
              "2      136745.97  423323.75  1153.1385  24.7678  \n",
              "3      136863.39  427912.64  1160.1010  29.8331  \n",
              "4      140410.20  432485.03  1164.3110  29.4290  \n",
              "..           ...        ...        ...      ...  \n",
              "262    369983.50  754662.69  5607.1160  19.1586  \n",
              "263    370554.92  753781.25  5678.9640  21.2985  \n",
              "264    370286.86  751635.23  5777.3631  22.9143  \n",
              "265    374193.90  753730.65  5818.5663  26.1429  \n",
              "266    369346.54  747716.57  5822.2776  26.9368  \n",
              "\n",
              "[267 rows x 99 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0f34cf3-3595-48df-b2ad-bf55a29b24f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RPI</th>\n",
              "      <th>W875RX1</th>\n",
              "      <th>DPCERA3M086SBEA</th>\n",
              "      <th>CMRMTSPLx</th>\n",
              "      <th>RETAILx</th>\n",
              "      <th>IPFPNSS</th>\n",
              "      <th>IPFINAL</th>\n",
              "      <th>IPDCONGD</th>\n",
              "      <th>IPNCONGD</th>\n",
              "      <th>IPBUSEQ</th>\n",
              "      <th>...</th>\n",
              "      <th>DNDGRG3M086SBEA</th>\n",
              "      <th>DSERRG3M086SBEA</th>\n",
              "      <th>CES0600000008</th>\n",
              "      <th>CES2000000008</th>\n",
              "      <th>CES3000000008</th>\n",
              "      <th>UMCSENTx</th>\n",
              "      <th>DTCOLNVHFNM</th>\n",
              "      <th>DTCTHFNM</th>\n",
              "      <th>INVEST</th>\n",
              "      <th>VIXCLSx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10861.073</td>\n",
              "      <td>9498.6</td>\n",
              "      <td>76.746</td>\n",
              "      <td>1129614</td>\n",
              "      <td>268044</td>\n",
              "      <td>99.3409</td>\n",
              "      <td>96.5258</td>\n",
              "      <td>98.4850</td>\n",
              "      <td>102.5384</td>\n",
              "      <td>83.8829</td>\n",
              "      <td>...</td>\n",
              "      <td>72.498</td>\n",
              "      <td>71.832</td>\n",
              "      <td>15.01</td>\n",
              "      <td>17.11</td>\n",
              "      <td>14.13</td>\n",
              "      <td>112.0</td>\n",
              "      <td>132467.09</td>\n",
              "      <td>421056.34</td>\n",
              "      <td>1147.6935</td>\n",
              "      <td>24.8430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10906.015</td>\n",
              "      <td>9541.8</td>\n",
              "      <td>77.468</td>\n",
              "      <td>1109286</td>\n",
              "      <td>272020</td>\n",
              "      <td>99.8416</td>\n",
              "      <td>97.1313</td>\n",
              "      <td>98.1898</td>\n",
              "      <td>103.7785</td>\n",
              "      <td>84.5120</td>\n",
              "      <td>...</td>\n",
              "      <td>73.025</td>\n",
              "      <td>72.046</td>\n",
              "      <td>15.06</td>\n",
              "      <td>17.20</td>\n",
              "      <td>14.14</td>\n",
              "      <td>111.3</td>\n",
              "      <td>136610.16</td>\n",
              "      <td>422437.48</td>\n",
              "      <td>1140.6992</td>\n",
              "      <td>25.4560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10936.525</td>\n",
              "      <td>9573.1</td>\n",
              "      <td>77.850</td>\n",
              "      <td>1122401</td>\n",
              "      <td>275192</td>\n",
              "      <td>100.0390</td>\n",
              "      <td>97.2144</td>\n",
              "      <td>97.8025</td>\n",
              "      <td>103.3591</td>\n",
              "      <td>85.6665</td>\n",
              "      <td>...</td>\n",
              "      <td>73.959</td>\n",
              "      <td>72.174</td>\n",
              "      <td>15.10</td>\n",
              "      <td>17.28</td>\n",
              "      <td>14.17</td>\n",
              "      <td>107.1</td>\n",
              "      <td>136745.97</td>\n",
              "      <td>423323.75</td>\n",
              "      <td>1153.1385</td>\n",
              "      <td>24.7678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10996.136</td>\n",
              "      <td>9620.5</td>\n",
              "      <td>77.827</td>\n",
              "      <td>1131729</td>\n",
              "      <td>271046</td>\n",
              "      <td>100.8609</td>\n",
              "      <td>98.0194</td>\n",
              "      <td>99.0959</td>\n",
              "      <td>104.0481</td>\n",
              "      <td>86.6401</td>\n",
              "      <td>...</td>\n",
              "      <td>73.660</td>\n",
              "      <td>72.207</td>\n",
              "      <td>15.17</td>\n",
              "      <td>17.39</td>\n",
              "      <td>14.23</td>\n",
              "      <td>109.2</td>\n",
              "      <td>136863.39</td>\n",
              "      <td>427912.64</td>\n",
              "      <td>1160.1010</td>\n",
              "      <td>29.8331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11035.828</td>\n",
              "      <td>9628.6</td>\n",
              "      <td>78.118</td>\n",
              "      <td>1125723</td>\n",
              "      <td>271394</td>\n",
              "      <td>101.0331</td>\n",
              "      <td>98.3635</td>\n",
              "      <td>98.7398</td>\n",
              "      <td>104.4840</td>\n",
              "      <td>87.4207</td>\n",
              "      <td>...</td>\n",
              "      <td>73.531</td>\n",
              "      <td>72.346</td>\n",
              "      <td>15.17</td>\n",
              "      <td>17.38</td>\n",
              "      <td>14.22</td>\n",
              "      <td>110.7</td>\n",
              "      <td>140410.20</td>\n",
              "      <td>432485.03</td>\n",
              "      <td>1164.3110</td>\n",
              "      <td>29.4290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>17801.835</td>\n",
              "      <td>14463.1</td>\n",
              "      <td>125.640</td>\n",
              "      <td>1572476</td>\n",
              "      <td>644741</td>\n",
              "      <td>101.2536</td>\n",
              "      <td>101.6843</td>\n",
              "      <td>104.7551</td>\n",
              "      <td>99.6725</td>\n",
              "      <td>95.9763</td>\n",
              "      <td>...</td>\n",
              "      <td>105.852</td>\n",
              "      <td>126.278</td>\n",
              "      <td>26.99</td>\n",
              "      <td>31.04</td>\n",
              "      <td>24.24</td>\n",
              "      <td>67.4</td>\n",
              "      <td>369983.50</td>\n",
              "      <td>754662.69</td>\n",
              "      <td>5607.1160</td>\n",
              "      <td>19.1586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>17791.488</td>\n",
              "      <td>14465.3</td>\n",
              "      <td>123.868</td>\n",
              "      <td>1562935</td>\n",
              "      <td>634393</td>\n",
              "      <td>100.8807</td>\n",
              "      <td>101.3610</td>\n",
              "      <td>103.9402</td>\n",
              "      <td>99.3044</td>\n",
              "      <td>95.9503</td>\n",
              "      <td>...</td>\n",
              "      <td>106.351</td>\n",
              "      <td>126.834</td>\n",
              "      <td>27.17</td>\n",
              "      <td>31.25</td>\n",
              "      <td>24.38</td>\n",
              "      <td>70.6</td>\n",
              "      <td>370554.92</td>\n",
              "      <td>753781.25</td>\n",
              "      <td>5678.9640</td>\n",
              "      <td>21.2985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>17711.363</td>\n",
              "      <td>14444.5</td>\n",
              "      <td>125.781</td>\n",
              "      <td>1581814</td>\n",
              "      <td>651557</td>\n",
              "      <td>101.7294</td>\n",
              "      <td>102.2818</td>\n",
              "      <td>105.6880</td>\n",
              "      <td>100.5197</td>\n",
              "      <td>95.5580</td>\n",
              "      <td>...</td>\n",
              "      <td>107.154</td>\n",
              "      <td>127.248</td>\n",
              "      <td>27.31</td>\n",
              "      <td>31.44</td>\n",
              "      <td>24.51</td>\n",
              "      <td>67.2</td>\n",
              "      <td>370286.86</td>\n",
              "      <td>751635.23</td>\n",
              "      <td>5777.3631</td>\n",
              "      <td>22.9143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>17727.726</td>\n",
              "      <td>14485.8</td>\n",
              "      <td>125.878</td>\n",
              "      <td>1570284</td>\n",
              "      <td>662321</td>\n",
              "      <td>102.9275</td>\n",
              "      <td>103.3749</td>\n",
              "      <td>103.8407</td>\n",
              "      <td>101.8127</td>\n",
              "      <td>97.3472</td>\n",
              "      <td>...</td>\n",
              "      <td>109.075</td>\n",
              "      <td>127.566</td>\n",
              "      <td>27.42</td>\n",
              "      <td>31.60</td>\n",
              "      <td>24.56</td>\n",
              "      <td>62.8</td>\n",
              "      <td>374193.90</td>\n",
              "      <td>753730.65</td>\n",
              "      <td>5818.5663</td>\n",
              "      <td>26.1429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>17666.265</td>\n",
              "      <td>14447.6</td>\n",
              "      <td>126.480</td>\n",
              "      <td>1551969</td>\n",
              "      <td>671648</td>\n",
              "      <td>103.6544</td>\n",
              "      <td>104.3039</td>\n",
              "      <td>107.3327</td>\n",
              "      <td>101.8590</td>\n",
              "      <td>98.7428</td>\n",
              "      <td>...</td>\n",
              "      <td>112.130</td>\n",
              "      <td>128.165</td>\n",
              "      <td>27.50</td>\n",
              "      <td>31.67</td>\n",
              "      <td>24.71</td>\n",
              "      <td>59.4</td>\n",
              "      <td>369346.54</td>\n",
              "      <td>747716.57</td>\n",
              "      <td>5822.2776</td>\n",
              "      <td>26.9368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>267 rows × 99 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0f34cf3-3595-48df-b2ad-bf55a29b24f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0f34cf3-3595-48df-b2ad-bf55a29b24f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0f34cf3-3595-48df-b2ad-bf55a29b24f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logisitc Regression"
      ],
      "metadata": {
        "id": "J5yoLeU9DeQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(777)\n",
        "\n",
        "#grid_search 이용\n",
        "X_train = X.iloc[0:266,:]\n",
        "Y_train = Y.iloc[0:266]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'max_iter' : [1000,20000]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, Y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "__az1qj9AsGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적의 parameters : ', grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8T6hrHEBk6R",
        "outputId": "f00ea0a8-69ac-4194-ec44-8fc78e0a6d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 parameters :  {'C': 0.01, 'max_iter': 1000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구축\n",
        "\n",
        "model = LogisticRegression(C = 10 , max_iter=30000, random_state=777)"
      ],
      "metadata": {
        "id": "C5gMaCi8Bqkl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.iloc[252:268,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "esKu6NMBtNSb",
        "outputId": "74433949-1534-4cbe-8a22-45e20049787e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           RPI  W875RX1  DPCERA3M086SBEA  CMRMTSPLx  RETAILx   IPFPNSS  \\\n",
              "252  19103.244  14031.9          119.498    1579345   572822   99.0915   \n",
              "253  17678.432  14028.9          117.905    1531244   562686   96.9818   \n",
              "254  21267.506  14124.2          123.299    1591781   625731   98.9656   \n",
              "255  18328.957  14199.2          123.866    1585058   626430   98.3697   \n",
              "256  17875.090  14242.7          123.253    1551428   620075   98.8980   \n",
              "257  17827.219  14277.9          123.981    1559335   626999   98.9005   \n",
              "258  17985.182  14345.8          123.593    1558848   620648  100.2765   \n",
              "259  17986.302  14340.7          124.496    1556107   624738  100.0586   \n",
              "260  17755.780  14372.5          124.826    1563118   630905   99.4979   \n",
              "261  17785.166  14440.2          125.740    1570449   640899  100.2852   \n",
              "262  17801.835  14463.1          125.640    1572476   644741  101.2536   \n",
              "263  17791.488  14465.3          123.868    1562935   634393  100.8807   \n",
              "264  17711.363  14444.5          125.781    1581814   651557  101.7294   \n",
              "265  17727.726  14485.8          125.878    1570284   662321  102.9275   \n",
              "266  17666.265  14447.6          126.480    1551969   671648  103.6544   \n",
              "\n",
              "      IPFINAL  IPDCONGD  IPNCONGD  IPBUSEQ  ...  DNDGRG3M086SBEA  \\\n",
              "252  100.0551  107.7847   98.8359  93.9628  ...           99.980   \n",
              "253   98.0210  100.1276   98.2046  91.2959  ...          100.456   \n",
              "254   99.7706  102.1429   99.2276  94.0118  ...          101.233   \n",
              "255   99.0437   99.2309   99.4554  92.3306  ...          101.516   \n",
              "256   99.7605  101.5654   99.5969  93.7686  ...          101.657   \n",
              "257   99.8743  100.0380   99.7533  93.2133  ...          102.223   \n",
              "258  101.4638  104.5418   99.7102  95.9640  ...          102.803   \n",
              "259  100.9565  102.4213   99.8629  95.0837  ...          103.225   \n",
              "260  100.0914   99.1582   99.5798  94.2317  ...          103.808   \n",
              "261  100.8200  103.9343   98.7532  95.2649  ...          104.958   \n",
              "262  101.6843  104.7551   99.6725  95.9763  ...          105.852   \n",
              "263  101.3610  103.9402   99.3044  95.9503  ...          106.351   \n",
              "264  102.2818  105.6880  100.5197  95.5580  ...          107.154   \n",
              "265  103.3749  103.8407  101.8127  97.3472  ...          109.075   \n",
              "266  104.3039  107.3327  101.8590  98.7428  ...          112.130   \n",
              "\n",
              "     DSERRG3M086SBEA  CES0600000008  CES2000000008  CES3000000008  UMCSENTx  \\\n",
              "252          121.742          25.88          29.71          23.27      79.0   \n",
              "253          121.992          25.94          29.82          23.39      76.8   \n",
              "254          122.594          26.00          29.84          23.40      84.9   \n",
              "255          123.120          26.16          30.12          23.48      88.3   \n",
              "256          123.565          26.31          30.27          23.64      82.9   \n",
              "257          124.093          26.44          30.43          23.77      85.5   \n",
              "258          124.557          26.58          30.61          23.89      81.2   \n",
              "259          124.913          26.73          30.76          24.03      70.3   \n",
              "260          125.243          26.81          30.76          24.10      72.8   \n",
              "261          125.652          26.88          30.95          24.17      71.7   \n",
              "262          126.278          26.99          31.04          24.24      67.4   \n",
              "263          126.834          27.17          31.25          24.38      70.6   \n",
              "264          127.248          27.31          31.44          24.51      67.2   \n",
              "265          127.566          27.42          31.60          24.56      62.8   \n",
              "266          128.165          27.50          31.67          24.71      59.4   \n",
              "\n",
              "     DTCOLNVHFNM   DTCTHFNM     INVEST  VIXCLSx  \n",
              "252    355240.05  738832.82  4774.7422  25.5982  \n",
              "253    355291.71  736048.95  4864.5907  22.5607  \n",
              "254    358586.15  743388.12  4976.8915  21.4680  \n",
              "255    362666.77  751213.18  5077.8221  17.1684  \n",
              "256    365154.60  754248.23  5182.9647  19.1336  \n",
              "257    366098.79  756290.99  5254.4912  16.9236  \n",
              "258    366126.54  756089.86  5299.2169  17.5754  \n",
              "259    366753.45  756588.86  5354.4097  17.0618  \n",
              "260    370236.20  758672.57  5418.2216  19.7806  \n",
              "261    369540.39  755823.28  5529.1918  17.7838  \n",
              "262    369983.50  754662.69  5607.1160  19.1586  \n",
              "263    370554.92  753781.25  5678.9640  21.2985  \n",
              "264    370286.86  751635.23  5777.3631  22.9143  \n",
              "265    374193.90  753730.65  5818.5663  26.1429  \n",
              "266    369346.54  747716.57  5822.2776  26.9368  \n",
              "\n",
              "[15 rows x 99 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1dd92df-ba5c-4524-ba77-8deb47a58ed6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RPI</th>\n",
              "      <th>W875RX1</th>\n",
              "      <th>DPCERA3M086SBEA</th>\n",
              "      <th>CMRMTSPLx</th>\n",
              "      <th>RETAILx</th>\n",
              "      <th>IPFPNSS</th>\n",
              "      <th>IPFINAL</th>\n",
              "      <th>IPDCONGD</th>\n",
              "      <th>IPNCONGD</th>\n",
              "      <th>IPBUSEQ</th>\n",
              "      <th>...</th>\n",
              "      <th>DNDGRG3M086SBEA</th>\n",
              "      <th>DSERRG3M086SBEA</th>\n",
              "      <th>CES0600000008</th>\n",
              "      <th>CES2000000008</th>\n",
              "      <th>CES3000000008</th>\n",
              "      <th>UMCSENTx</th>\n",
              "      <th>DTCOLNVHFNM</th>\n",
              "      <th>DTCTHFNM</th>\n",
              "      <th>INVEST</th>\n",
              "      <th>VIXCLSx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>19103.244</td>\n",
              "      <td>14031.9</td>\n",
              "      <td>119.498</td>\n",
              "      <td>1579345</td>\n",
              "      <td>572822</td>\n",
              "      <td>99.0915</td>\n",
              "      <td>100.0551</td>\n",
              "      <td>107.7847</td>\n",
              "      <td>98.8359</td>\n",
              "      <td>93.9628</td>\n",
              "      <td>...</td>\n",
              "      <td>99.980</td>\n",
              "      <td>121.742</td>\n",
              "      <td>25.88</td>\n",
              "      <td>29.71</td>\n",
              "      <td>23.27</td>\n",
              "      <td>79.0</td>\n",
              "      <td>355240.05</td>\n",
              "      <td>738832.82</td>\n",
              "      <td>4774.7422</td>\n",
              "      <td>25.5982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>17678.432</td>\n",
              "      <td>14028.9</td>\n",
              "      <td>117.905</td>\n",
              "      <td>1531244</td>\n",
              "      <td>562686</td>\n",
              "      <td>96.9818</td>\n",
              "      <td>98.0210</td>\n",
              "      <td>100.1276</td>\n",
              "      <td>98.2046</td>\n",
              "      <td>91.2959</td>\n",
              "      <td>...</td>\n",
              "      <td>100.456</td>\n",
              "      <td>121.992</td>\n",
              "      <td>25.94</td>\n",
              "      <td>29.82</td>\n",
              "      <td>23.39</td>\n",
              "      <td>76.8</td>\n",
              "      <td>355291.71</td>\n",
              "      <td>736048.95</td>\n",
              "      <td>4864.5907</td>\n",
              "      <td>22.5607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>21267.506</td>\n",
              "      <td>14124.2</td>\n",
              "      <td>123.299</td>\n",
              "      <td>1591781</td>\n",
              "      <td>625731</td>\n",
              "      <td>98.9656</td>\n",
              "      <td>99.7706</td>\n",
              "      <td>102.1429</td>\n",
              "      <td>99.2276</td>\n",
              "      <td>94.0118</td>\n",
              "      <td>...</td>\n",
              "      <td>101.233</td>\n",
              "      <td>122.594</td>\n",
              "      <td>26.00</td>\n",
              "      <td>29.84</td>\n",
              "      <td>23.40</td>\n",
              "      <td>84.9</td>\n",
              "      <td>358586.15</td>\n",
              "      <td>743388.12</td>\n",
              "      <td>4976.8915</td>\n",
              "      <td>21.4680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>18328.957</td>\n",
              "      <td>14199.2</td>\n",
              "      <td>123.866</td>\n",
              "      <td>1585058</td>\n",
              "      <td>626430</td>\n",
              "      <td>98.3697</td>\n",
              "      <td>99.0437</td>\n",
              "      <td>99.2309</td>\n",
              "      <td>99.4554</td>\n",
              "      <td>92.3306</td>\n",
              "      <td>...</td>\n",
              "      <td>101.516</td>\n",
              "      <td>123.120</td>\n",
              "      <td>26.16</td>\n",
              "      <td>30.12</td>\n",
              "      <td>23.48</td>\n",
              "      <td>88.3</td>\n",
              "      <td>362666.77</td>\n",
              "      <td>751213.18</td>\n",
              "      <td>5077.8221</td>\n",
              "      <td>17.1684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>17875.090</td>\n",
              "      <td>14242.7</td>\n",
              "      <td>123.253</td>\n",
              "      <td>1551428</td>\n",
              "      <td>620075</td>\n",
              "      <td>98.8980</td>\n",
              "      <td>99.7605</td>\n",
              "      <td>101.5654</td>\n",
              "      <td>99.5969</td>\n",
              "      <td>93.7686</td>\n",
              "      <td>...</td>\n",
              "      <td>101.657</td>\n",
              "      <td>123.565</td>\n",
              "      <td>26.31</td>\n",
              "      <td>30.27</td>\n",
              "      <td>23.64</td>\n",
              "      <td>82.9</td>\n",
              "      <td>365154.60</td>\n",
              "      <td>754248.23</td>\n",
              "      <td>5182.9647</td>\n",
              "      <td>19.1336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17827.219</td>\n",
              "      <td>14277.9</td>\n",
              "      <td>123.981</td>\n",
              "      <td>1559335</td>\n",
              "      <td>626999</td>\n",
              "      <td>98.9005</td>\n",
              "      <td>99.8743</td>\n",
              "      <td>100.0380</td>\n",
              "      <td>99.7533</td>\n",
              "      <td>93.2133</td>\n",
              "      <td>...</td>\n",
              "      <td>102.223</td>\n",
              "      <td>124.093</td>\n",
              "      <td>26.44</td>\n",
              "      <td>30.43</td>\n",
              "      <td>23.77</td>\n",
              "      <td>85.5</td>\n",
              "      <td>366098.79</td>\n",
              "      <td>756290.99</td>\n",
              "      <td>5254.4912</td>\n",
              "      <td>16.9236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>17985.182</td>\n",
              "      <td>14345.8</td>\n",
              "      <td>123.593</td>\n",
              "      <td>1558848</td>\n",
              "      <td>620648</td>\n",
              "      <td>100.2765</td>\n",
              "      <td>101.4638</td>\n",
              "      <td>104.5418</td>\n",
              "      <td>99.7102</td>\n",
              "      <td>95.9640</td>\n",
              "      <td>...</td>\n",
              "      <td>102.803</td>\n",
              "      <td>124.557</td>\n",
              "      <td>26.58</td>\n",
              "      <td>30.61</td>\n",
              "      <td>23.89</td>\n",
              "      <td>81.2</td>\n",
              "      <td>366126.54</td>\n",
              "      <td>756089.86</td>\n",
              "      <td>5299.2169</td>\n",
              "      <td>17.5754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>17986.302</td>\n",
              "      <td>14340.7</td>\n",
              "      <td>124.496</td>\n",
              "      <td>1556107</td>\n",
              "      <td>624738</td>\n",
              "      <td>100.0586</td>\n",
              "      <td>100.9565</td>\n",
              "      <td>102.4213</td>\n",
              "      <td>99.8629</td>\n",
              "      <td>95.0837</td>\n",
              "      <td>...</td>\n",
              "      <td>103.225</td>\n",
              "      <td>124.913</td>\n",
              "      <td>26.73</td>\n",
              "      <td>30.76</td>\n",
              "      <td>24.03</td>\n",
              "      <td>70.3</td>\n",
              "      <td>366753.45</td>\n",
              "      <td>756588.86</td>\n",
              "      <td>5354.4097</td>\n",
              "      <td>17.0618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>17755.780</td>\n",
              "      <td>14372.5</td>\n",
              "      <td>124.826</td>\n",
              "      <td>1563118</td>\n",
              "      <td>630905</td>\n",
              "      <td>99.4979</td>\n",
              "      <td>100.0914</td>\n",
              "      <td>99.1582</td>\n",
              "      <td>99.5798</td>\n",
              "      <td>94.2317</td>\n",
              "      <td>...</td>\n",
              "      <td>103.808</td>\n",
              "      <td>125.243</td>\n",
              "      <td>26.81</td>\n",
              "      <td>30.76</td>\n",
              "      <td>24.10</td>\n",
              "      <td>72.8</td>\n",
              "      <td>370236.20</td>\n",
              "      <td>758672.57</td>\n",
              "      <td>5418.2216</td>\n",
              "      <td>19.7806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>17785.166</td>\n",
              "      <td>14440.2</td>\n",
              "      <td>125.740</td>\n",
              "      <td>1570449</td>\n",
              "      <td>640899</td>\n",
              "      <td>100.2852</td>\n",
              "      <td>100.8200</td>\n",
              "      <td>103.9343</td>\n",
              "      <td>98.7532</td>\n",
              "      <td>95.2649</td>\n",
              "      <td>...</td>\n",
              "      <td>104.958</td>\n",
              "      <td>125.652</td>\n",
              "      <td>26.88</td>\n",
              "      <td>30.95</td>\n",
              "      <td>24.17</td>\n",
              "      <td>71.7</td>\n",
              "      <td>369540.39</td>\n",
              "      <td>755823.28</td>\n",
              "      <td>5529.1918</td>\n",
              "      <td>17.7838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>17801.835</td>\n",
              "      <td>14463.1</td>\n",
              "      <td>125.640</td>\n",
              "      <td>1572476</td>\n",
              "      <td>644741</td>\n",
              "      <td>101.2536</td>\n",
              "      <td>101.6843</td>\n",
              "      <td>104.7551</td>\n",
              "      <td>99.6725</td>\n",
              "      <td>95.9763</td>\n",
              "      <td>...</td>\n",
              "      <td>105.852</td>\n",
              "      <td>126.278</td>\n",
              "      <td>26.99</td>\n",
              "      <td>31.04</td>\n",
              "      <td>24.24</td>\n",
              "      <td>67.4</td>\n",
              "      <td>369983.50</td>\n",
              "      <td>754662.69</td>\n",
              "      <td>5607.1160</td>\n",
              "      <td>19.1586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>17791.488</td>\n",
              "      <td>14465.3</td>\n",
              "      <td>123.868</td>\n",
              "      <td>1562935</td>\n",
              "      <td>634393</td>\n",
              "      <td>100.8807</td>\n",
              "      <td>101.3610</td>\n",
              "      <td>103.9402</td>\n",
              "      <td>99.3044</td>\n",
              "      <td>95.9503</td>\n",
              "      <td>...</td>\n",
              "      <td>106.351</td>\n",
              "      <td>126.834</td>\n",
              "      <td>27.17</td>\n",
              "      <td>31.25</td>\n",
              "      <td>24.38</td>\n",
              "      <td>70.6</td>\n",
              "      <td>370554.92</td>\n",
              "      <td>753781.25</td>\n",
              "      <td>5678.9640</td>\n",
              "      <td>21.2985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>17711.363</td>\n",
              "      <td>14444.5</td>\n",
              "      <td>125.781</td>\n",
              "      <td>1581814</td>\n",
              "      <td>651557</td>\n",
              "      <td>101.7294</td>\n",
              "      <td>102.2818</td>\n",
              "      <td>105.6880</td>\n",
              "      <td>100.5197</td>\n",
              "      <td>95.5580</td>\n",
              "      <td>...</td>\n",
              "      <td>107.154</td>\n",
              "      <td>127.248</td>\n",
              "      <td>27.31</td>\n",
              "      <td>31.44</td>\n",
              "      <td>24.51</td>\n",
              "      <td>67.2</td>\n",
              "      <td>370286.86</td>\n",
              "      <td>751635.23</td>\n",
              "      <td>5777.3631</td>\n",
              "      <td>22.9143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>17727.726</td>\n",
              "      <td>14485.8</td>\n",
              "      <td>125.878</td>\n",
              "      <td>1570284</td>\n",
              "      <td>662321</td>\n",
              "      <td>102.9275</td>\n",
              "      <td>103.3749</td>\n",
              "      <td>103.8407</td>\n",
              "      <td>101.8127</td>\n",
              "      <td>97.3472</td>\n",
              "      <td>...</td>\n",
              "      <td>109.075</td>\n",
              "      <td>127.566</td>\n",
              "      <td>27.42</td>\n",
              "      <td>31.60</td>\n",
              "      <td>24.56</td>\n",
              "      <td>62.8</td>\n",
              "      <td>374193.90</td>\n",
              "      <td>753730.65</td>\n",
              "      <td>5818.5663</td>\n",
              "      <td>26.1429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>17666.265</td>\n",
              "      <td>14447.6</td>\n",
              "      <td>126.480</td>\n",
              "      <td>1551969</td>\n",
              "      <td>671648</td>\n",
              "      <td>103.6544</td>\n",
              "      <td>104.3039</td>\n",
              "      <td>107.3327</td>\n",
              "      <td>101.8590</td>\n",
              "      <td>98.7428</td>\n",
              "      <td>...</td>\n",
              "      <td>112.130</td>\n",
              "      <td>128.165</td>\n",
              "      <td>27.50</td>\n",
              "      <td>31.67</td>\n",
              "      <td>24.71</td>\n",
              "      <td>59.4</td>\n",
              "      <td>369346.54</td>\n",
              "      <td>747716.57</td>\n",
              "      <td>5822.2776</td>\n",
              "      <td>26.9368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows × 99 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1dd92df-ba5c-4524-ba77-8deb47a58ed6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1dd92df-ba5c-4524-ba77-8deb47a58ed6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1dd92df-ba5c-4524-ba77-8deb47a58ed6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "for i in range(0,15) :\n",
        "\n",
        "  X_train = X.iloc[0:252+i, :]\n",
        "  Y_train = Y.iloc[0:252+i]\n",
        "\n",
        "  model.fit(X_train,Y_train)\n",
        "\n",
        "  X_test = X.iloc[252+i,:]\n",
        "  pred.append( int(model.predict(X_test.array.reshape(1,-1))) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDX7rICaFYLB",
        "outputId": "7dc074dd-1aa8-4612-a1ac-c46756bd511f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwHFxQtAGjr7",
        "outputId": "5d7d128b-c229-4f29-f32c-99c80b0288b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test = Y.iloc[252:269]\n",
        "\n",
        "len(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sxnkhPFHmmJ",
        "outputId": "105a975d-a070-4a60-df45-b98c9e5b1ffa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL0rwrY9JoTv",
        "outputId": "991ac206-d094-4493-a11b-c3157b8c1ebb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuJAY71_Jhtg",
        "outputId": "4f3a56e2-049f-41cf-8fc2-d8d95d1ec3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(np.array(Y_test), np.array(pred))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(np.array(Y_test), np.array(pred)).ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6c4kBqLLpmT",
        "outputId": "c8f2d402-0ef7-4d26-d283-e0998cfccf2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3, 4, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy =  (tp+tn)/(tp+tn+fp+fn)\n",
        "print('Accuracy : ', accuracy)\n",
        "\n",
        "# Precision\n",
        "precision = tp/(tp+fp)\n",
        "print('Precision : ', precision)\n",
        "\n",
        "# Recall\n",
        "recall = tp/(tp+fn)\n",
        "print('Recall : ', recall)\n",
        "\n",
        "# TPR\n",
        "tpr = tp / 8\n",
        "print('TPR : ', tpr)\n",
        "\n",
        "# FPR\n",
        "fpr = tn / 4\n",
        "print('FPR : ' , fpr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu_MgUtINHr2",
        "outputId": "f38ad620-7e1d-4f57-bf06-98ab12bc6b89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.5333333333333333\n",
            "Precision :  0.6666666666666666\n",
            "Recall :  0.6\n",
            "TPR :  0.75\n",
            "FPR :  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('roc auc value {}'.format(roc_auc_score(Y_test,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKVwNuQ8R2SV",
        "outputId": "d28dd2d0-e176-4dec-9b55-b943a15e8078"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc auc value 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "qpqYvapTUB4E",
        "outputId": "dfafc535-a5c6-46fd-fa8a-2e4bee02bfb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-ddac17eaef8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mthis\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수 중요도\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "model_fit = model.fit(X_train, Y_train)\n",
        "cross_val_score(model_fit, X_train, Y_train, cv=5)\n",
        "\n",
        "\n",
        "feature_importance_lr = pd.DataFrame(zip(X.columns.values, model_fit.coef_.ravel()))\n",
        "feature_importance_lr.columns = ['feature', 'coef']\n",
        "feature_importance_lr.sort_values(\"coef\", ascending=False, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUlz8L27xOqf",
        "outputId": "5881d445-0fb9-4a68-cc4c-b02a634e776d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance_lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BdFpAzkl2xVD",
        "outputId": "f0f7a53a-4e8f-4273-91ee-6f0b4d2992b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    feature      coef\n",
              "38   USFIRE  0.002859\n",
              "52   M2REAL  0.002839\n",
              "51     M2SL  0.002409\n",
              "21  UEMPLT5  0.000871\n",
              "28   USGOOD  0.000837\n",
              "..      ...       ...\n",
              "1   W875RX1 -0.001187\n",
              "97   INVEST -0.001250\n",
              "35    USTPU -0.002193\n",
              "43    HOUST -0.002711\n",
              "39   USGOVT -0.003755\n",
              "\n",
              "[99 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20c453e7-3ceb-4992-b457-3b1a1c2ad33b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>USFIRE</td>\n",
              "      <td>0.002859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>M2REAL</td>\n",
              "      <td>0.002839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>M2SL</td>\n",
              "      <td>0.002409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>UEMPLT5</td>\n",
              "      <td>0.000871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>USGOOD</td>\n",
              "      <td>0.000837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>W875RX1</td>\n",
              "      <td>-0.001187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>INVEST</td>\n",
              "      <td>-0.001250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>USTPU</td>\n",
              "      <td>-0.002193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>HOUST</td>\n",
              "      <td>-0.002711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>USGOVT</td>\n",
              "      <td>-0.003755</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20c453e7-3ceb-4992-b457-3b1a1c2ad33b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20c453e7-3ceb-4992-b457-3b1a1c2ad33b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20c453e7-3ceb-4992-b457-3b1a1c2ad33b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance_pos = feature_importance_lr[0:5]\n",
        "\n",
        "# 지수 상승할 확률 Rate배 증가 \n",
        "feature_importance_pos['Rate'] = np.exp(feature_importance_pos['coef'])\n",
        "feature_importance_pos\n",
        "\n",
        "del feature_importance_pos['coef']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cexklglV2zRH",
        "outputId": "eea2da15-23f7-4ced-ea77-d69e6628be81"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance_neg = feature_importance_lr[-5:]\n",
        "\n",
        "# 지수 상승할 확률 Rate배 감소\n",
        "feature_importance_neg['Rate'] = 1 - np.exp(feature_importance_neg['coef'])\n",
        "feature_importance_neg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "d-67BVtc6FGM",
        "outputId": "900b33ad-b37a-4b2b-e304-23112e8d97e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature      coef      Rate\n",
              "34  SRVPRD -0.000496  0.000496\n",
              "35   USTPU -0.000570  0.000570\n",
              "43   HOUST -0.000593  0.000593\n",
              "50    M1SL -0.000696  0.000696\n",
              "39  USGOVT -0.001537  0.001535"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-969f67cb-551a-490f-9489-ae3143ad81d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>coef</th>\n",
              "      <th>Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>SRVPRD</td>\n",
              "      <td>-0.000496</td>\n",
              "      <td>0.000496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>USTPU</td>\n",
              "      <td>-0.000570</td>\n",
              "      <td>0.000570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>HOUST</td>\n",
              "      <td>-0.000593</td>\n",
              "      <td>0.000593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>M1SL</td>\n",
              "      <td>-0.000696</td>\n",
              "      <td>0.000696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>USGOVT</td>\n",
              "      <td>-0.001537</td>\n",
              "      <td>0.001535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-969f67cb-551a-490f-9489-ae3143ad81d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-969f67cb-551a-490f-9489-ae3143ad81d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-969f67cb-551a-490f-9489-ae3143ad81d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tree 사용\n",
        "\n",
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(777)\n"
      ],
      "metadata": {
        "id": "IoNQTsJR61v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "FhWd-4H1VX28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search\n",
        "\n",
        "np.random.seed(777)\n",
        "\n",
        "#grid_search 이용\n",
        "X_train = X.iloc[0:266,:]\n",
        "Y_train = Y.iloc[0:266]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = { 'n_estimators' : [100, 200,300],\n",
        "           'max_depth' : [6, 8, 10, 12, 16, 20],\n",
        "           'min_samples_leaf' : [8, 12, 18],\n",
        "           'min_samples_split' : [8,16,20] # 작을수록 overfitting\n",
        "            \n",
        "            }\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state = 777, n_jobs = -1)\n",
        "grid_search = GridSearchCV(rf_clf, param_grid, cv=5 , refit=True, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogOacZvEaDtU",
        "outputId": "18feb658-6356-48de-ae74-fdea564086dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=RandomForestClassifier(n_jobs=-1, random_state=777),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_depth': [6, 8, 10, 12, 16, 20],\n",
              "                         'min_samples_leaf': [8, 12, 18],\n",
              "                         'min_samples_split': [8, 16, 20],\n",
              "                         'n_estimators': [100, 200, 300]})"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적의 parameters : ', grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trthIwROciaf",
        "outputId": "11b3d29c-a4f0-4697-a78d-c4949dd11ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 parameters :  {'max_depth': 6, 'min_samples_leaf': 18, 'min_samples_split': 8, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    min_samples_leaf=18,\n",
        "    min_samples_split=16,\n",
        "    random_state=777,\n",
        "    n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "id": "GofYDt-ydaHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "for i in range(0,15) :\n",
        "\n",
        "  X_train = X.iloc[0:252+i, :]\n",
        "  Y_train = Y.iloc[0:252+i]\n",
        "\n",
        "  rf_clf.fit(X_train,Y_train)\n",
        "\n",
        "  X_test = X.iloc[252+i,:]\n",
        "  pred.append( int(rf_clf.predict(X_test.array.reshape(1,-1))) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sJnBWKoXWXo",
        "outputId": "397d54a6-e4a9-471e-a8a8-58a30fac3b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-qCSg2mdr0f",
        "outputId": "1bde74f7-840e-47d5-9f91-20ec9588f1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test= Y.iloc[252:267]\n",
        "len(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTN5exkefLrn",
        "outputId": "65488321-efef-4420-8de8-730024c435db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(np.array(Y_test), np.array(pred))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(np.array(Y_test), np.array(pred)).ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhox7LzGeT-s",
        "outputId": "ebde7bd2-2478-493b-a87e-5c5fa3642102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 5, 1, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy =  (tp+tn)/(tp+tn+fp+fn)\n",
        "print('Accuracy : ', accuracy)\n",
        "\n",
        "# Precision\n",
        "precision = tp/(tp+fp)\n",
        "print('Precision : ', precision)\n",
        "\n",
        "# Recall\n",
        "recall = tp/(tp+fn)\n",
        "print('Recall : ', recall)\n",
        "\n",
        "# TPR\n",
        "tpr = tp / 8\n",
        "print('TPR : ', tpr)\n",
        "\n",
        "# FPR\n",
        "fpr = tn / 4\n",
        "print('FPR : ' , fpr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDdWJLd_eYyk",
        "outputId": "4a13bbd4-7069-4d68-aecc-04094361234f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.6\n",
            "Precision :  0.6428571428571429\n",
            "Recall :  0.9\n",
            "TPR :  1.125\n",
            "FPR :  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('roc auc value {}'.format(roc_auc_score(Y_test,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KleE0dbteaC5",
        "outputId": "0fe6afc2-9775-41e8-b0d4-9a2de4a0959d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc auc value 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.score(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9xSnbZPeho_",
        "outputId": "64c16c04-fd26-4bed-b290-c77a77deb660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7142857142857143"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **과적합 현상 발생, 변수 축소**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-4Kmqx5_rZAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "\n",
        "X =  pd.read_csv('/content/drive/My Drive/finbert/FRED.csv')\n",
        "\n",
        "Y = pd.read_csv('/content/drive/My Drive/finbert/S&P500.csv')"
      ],
      "metadata": {
        "id": "hAmoZfTC4Dmj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수 축소\n",
        "\n",
        "\n",
        "feature_re =  pd.read_csv('/content/drive/My Drive/finbert/new_feature.csv')\n",
        "\n",
        "del X['sasdate']\n",
        "\n",
        "Y = Y['Result']\n",
        "\n",
        "X.rename(columns={'IPB51222S':'IPB51222s'},inplace=True)\n",
        "\n",
        "X = X.fillna(0)\n",
        "\n",
        "\n",
        "# 변수 선택\n",
        "\n",
        "new_feature_name = feature_re['fred']\n",
        "\n",
        "X = X.loc[:,new_feature_name]\n",
        "\n",
        "del X['Positive']\n",
        "del X['Negative']\n",
        "del X['Neutral']\n",
        "\n"
      ],
      "metadata": {
        "id": "GNKwVFjpgtB9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "S3tN0TgVTC-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(777)\n",
        "\n",
        "#grid_search 이용\n",
        "X_train = X.iloc[0:266,:]\n",
        "Y_train = Y.iloc[0:266]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'max_iter' : [1000,10000,20000]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, Y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2vJv6NETDZN",
        "outputId": "8f4ba754-d90b-442d-ebda-a0b3a7716d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
              "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
              "                         'max_iter': [1000, 20000]})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적의 parameters : ', grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv_bPaVJTDbN",
        "outputId": "36bf1920-eae5-4191-db2b-3086ad1e8d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 parameters :  {'learning_rate': 0.001, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit_clf = LogisticRegression(\n",
        "    random_state = 777,\n",
        "    C = 0.1,\n",
        "    max_iter = 20000\n",
        ")\n",
        "\n",
        "\n",
        "pred = []\n",
        "for i in range(0,15) :\n",
        "\n",
        "  X_train = X.iloc[0:252+i, :]\n",
        "  Y_train = Y.iloc[0:252+i]\n",
        "\n",
        "  logit_clf.fit(X_train,Y_train)\n",
        "\n",
        "  X_test = X.iloc[252+i,:]\n",
        "  pred.append( int(logit_clf.predict(X_test.array.reshape(1,-1))) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OebgoofTDec",
        "outputId": "fe8b0d0e-cc3f-49a8-d257-74ebc1e70520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNFBMF6WVA_z",
        "outputId": "71d6339e-bb91-4046-b528-41386e424537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "Y_test= Y.iloc[252:267]\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(np.array(Y_test), np.array(pred))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(np.array(Y_test), np.array(pred)).ravel()\n",
        "(tn, fp, fn, tp)\n",
        "\n",
        "# Accuracy\n",
        "accuracy =  (tp+tn)/(tp+tn+fp+fn)\n",
        "print('Accuracy : ', accuracy)\n",
        "\n",
        "# Precision\n",
        "precision = tp/(tp+fp)\n",
        "print('Precision : ', precision)\n",
        "\n",
        "# Recall\n",
        "recall = tp/(tp+fn)\n",
        "print('Recall : ', recall)\n",
        "\n",
        "# TPR\n",
        "tpr = tp / 8\n",
        "print('TPR : ', tpr)\n",
        "\n",
        "# FPR\n",
        "fpr = tn / 4\n",
        "print('FPR : ' , fpr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4p_zjrOVBB0",
        "outputId": "fa18a5f0-29c5-41d9-913b-bccf6dfdc896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.6666666666666666\n",
            "Precision :  0.6923076923076923\n",
            "Recall :  0.9\n",
            "TPR :  1.125\n",
            "FPR :  0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('roc auc value {}'.format(roc_auc_score(Y_test,pred)))\n",
        "\n",
        "logit_clf.score(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JomRF6tNU7mo",
        "outputId": "2e5012de-332f-4035-fd47-e01cd042dd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc auc value 0.55\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6729323308270677"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandomForest"
      ],
      "metadata": {
        "id": "aaP9nPejO2e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "VGo13vzYTSYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(777)\n",
        "\n",
        "#grid_search 이용\n",
        "X_train = X.iloc[0:266,:]\n",
        "Y_train = Y.iloc[0:266]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = { 'n_estimators' : [100, 200,300],\n",
        "           'max_depth' : [6, 8, 10, 12, 16, 20],\n",
        "           'min_samples_leaf' : [5, 7, 10,12],\n",
        "           'min_samples_split' : [3,5,7,10,12] # 작을수록 overfitting\n",
        "            }\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state = 777, n_jobs = -1)\n",
        "grid_search = GridSearchCV(rf_clf, param_grid, cv=5 , refit=True, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGj9lwrg4IgV",
        "outputId": "6e427c00-5804-43d3-bd9f-6e894638d519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=RandomForestClassifier(n_jobs=-1, random_state=777),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_depth': [6, 8, 10, 12, 16, 20],\n",
              "                         'min_samples_leaf': [5, 7, 10, 12],\n",
              "                         'min_samples_split': [3, 5, 7, 10, 12],\n",
              "                         'n_estimators': [100, 200, 300]})"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적의 parameters : ', grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsMEzmq_4zd_",
        "outputId": "7723e94a-dc67-4f13-a2c2-1b418ad756be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 parameters :  {'max_depth': 6, 'min_samples_leaf': 12, 'min_samples_split': 3, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest 재적합\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    min_samples_leaf=12,\n",
        "    min_samples_split=3,\n",
        "    random_state=777,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "pred = []\n",
        "for i in range(0,15) :\n",
        "\n",
        "  X_train = X.iloc[0:252+i, :]\n",
        "  Y_train = Y.iloc[0:252+i]\n",
        "\n",
        "  rf_clf.fit(X_train,Y_train)\n",
        "\n",
        "  X_test = X.iloc[252+i,:]\n",
        "  pred.append( int(rf_clf.predict(X_test.array.reshape(1,-1))) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjSHnEi4v668",
        "outputId": "1ebceb26-422a-415e-f658-bb9310eb6df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfeBUm-hwkvd",
        "outputId": "d5e690e1-ad8c-4425-e097-d44bb35a66bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw9fVTmp6Jfl",
        "outputId": "fc355ec4-158c-48a4-be13-77f8904bd729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252    0\n",
            "253    1\n",
            "254    1\n",
            "255    1\n",
            "256    1\n",
            "257    1\n",
            "258    1\n",
            "259    1\n",
            "260    0\n",
            "261    1\n",
            "262    0\n",
            "263    1\n",
            "264    0\n",
            "265    0\n",
            "266    1\n",
            "Name: Result, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "Y_test= Y.iloc[252:267]\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(np.array(Y_test), np.array(pred))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(np.array(Y_test), np.array(pred)).ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRJZeKoRwsVs",
        "outputId": "ced015bc-baa3-4689-fe26-c3c0e23803bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4, 1, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy =  (tp+tn)/(tp+tn+fp+fn)\n",
        "print('Accuracy : ', accuracy)\n",
        "\n",
        "# Precision\n",
        "precision = tp/(tp+fp)\n",
        "print('Precision : ', precision)\n",
        "\n",
        "# Recall\n",
        "recall = tp/(tp+fn)\n",
        "print('Recall : ', recall)\n",
        "\n",
        "# TPR\n",
        "tpr = tp / 8\n",
        "print('TPR : ', tpr)\n",
        "\n",
        "# FPR\n",
        "fpr = tn / 4\n",
        "print('FPR : ' , fpr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaJsot8cwtLv",
        "outputId": "2d87c203-8cec-4b10-9643-de1339bb6bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.6666666666666666\n",
            "Precision :  0.6923076923076923\n",
            "Recall :  0.9\n",
            "TPR :  1.125\n",
            "FPR :  0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('roc auc value {}'.format(roc_auc_score(Y_test,pred)))\n",
        "\n",
        "rf_clf.score(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uAt8VtLwyBY",
        "outputId": "e5b41fbd-6fc8-41c6-a3b3-bcb54c7cdbb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc auc value 0.55\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7481203007518797"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADABOOST"
      ],
      "metadata": {
        "id": "zQxXHxoeOwjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "metadata": {
        "id": "zgwwji23QCXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search\n",
        "\n",
        "np.random.seed(777)\n",
        "\n",
        "#grid_search 이용\n",
        "X_train = X.iloc[0:266,:]\n",
        "Y_train = Y.iloc[0:266]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = { 'n_estimators' : [100, 200,300],\n",
        "               'learning_rate' : [0.001, 0.01, 0.1, 0.5, 1]\n",
        "            }\n",
        "\n",
        "ada_clf = AdaBoostClassifier(random_state = 777)\n",
        "grid_search = GridSearchCV(ada_clf, param_grid)\n",
        "grid_search.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEhZd8pbQAk0",
        "outputId": "2ca69e8c-e74c-43f8-dea6-2bd46f7283bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=AdaBoostClassifier(random_state=777),\n",
              "             param_grid={'learning_rate': [0.001, 0.01, 0.1, 0.5, 1],\n",
              "                         'n_estimators': [100, 200, 300]})"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적의 parameters : ', grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7l46AEZQ1O_",
        "outputId": "2ceb0994-a652-4ee8-ed04-9e906a6f82dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 parameters :  {'learning_rate': 0.001, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ADABoost 적합\n",
        "\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    learning_rate = 0.001,\n",
        "    n_estimators=100,\n",
        "    random_state=777\n",
        ")\n",
        "\n",
        "pred = []\n",
        "for i in range(0,15) :\n",
        "\n",
        "  X_train = X.iloc[0:252+i, :]\n",
        "  Y_train = Y.iloc[0:252+i]\n",
        "\n",
        "  ada_clf.fit(X_train,Y_train)\n",
        "\n",
        "  X_test = X.iloc[252+i,:]\n",
        "  pred.append( int(ada_clf.predict(X_test.array.reshape(1,-1))) )"
      ],
      "metadata": {
        "id": "-jUArqBVw051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37530a66-752b-4291-a49b-d4ec3072b03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYKaftmRQy46",
        "outputId": "c5545d68-3bae-45b0-946c-ee814c6777cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "Y_test= Y.iloc[252:267]\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(np.array(Y_test), np.array(pred))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(np.array(Y_test), np.array(pred)).ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M88c2YTRFoI",
        "outputId": "f69fc295-25fc-4e92-9133-65b15fb58c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 0, 5, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy =  (tp+tn)/(tp+tn+fp+fn)\n",
        "print('Accuracy : ', accuracy)\n",
        "\n",
        "# Precision\n",
        "precision = tp/(tp+fp)\n",
        "print('Precision : ', precision)\n",
        "\n",
        "# Recall\n",
        "recall = tp/(tp+fn)\n",
        "print('Recall : ', recall)\n",
        "\n",
        "# TPR\n",
        "tpr = tp / 8\n",
        "print('TPR : ', tpr)\n",
        "\n",
        "# FPR\n",
        "fpr = tn / 4\n",
        "print('FPR : ' , fpr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFqSMmzZRwrz",
        "outputId": "16c30c8f-62e3-4534-edc0-0a2f68e32707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.6666666666666666\n",
            "Precision :  1.0\n",
            "Recall :  0.5\n",
            "TPR :  0.625\n",
            "FPR :  1.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('roc auc value {}'.format(roc_auc_score(Y_test,pred)))\n",
        "\n",
        "print('training score : ',ada_clf.score(X_train,Y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7ZHVsI5Ryh8",
        "outputId": "3271643a-2454-4da0-a988-be485a5545f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc auc value 0.75\n",
            "training score :  0.6691729323308271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "Dc6MMnwQS8u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "gvf0zhxJXYoo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search\n",
        "\n",
        "np.random.seed(777)\n",
        "\n",
        "#grid_search 이용\n",
        "X_train = X.iloc[0:266,:]\n",
        "Y_train = Y.iloc[0:266]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {  \n",
        "           'n_estimators' : [100,200,300,500,700,1000],\n",
        "           'max_depth' : [3,4,5,6, 8, 10, 12],\n",
        "           'learning_rate' : [0.001,0.003,0.01,0.03,0.1,0.3],\n",
        "            'objective' : ['binary:logistic'],\n",
        "            'min_child_weight' : [1,3,5,7,10],\n",
        "            'gamma' : [0,1] \n",
        "            \n",
        "            }\n",
        "\n",
        "xgb_clf = XGBClassifier(random_state = 777)\n",
        "grid_search = GridSearchCV(xgb_clf, param_grid)\n",
        "grid_search.fit(X_train, Y_train)\n",
        "\n",
        "print('최적의 parameters : ', grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJQ7uzqvW-WR",
        "outputId": "8019501b-1cbb-481a-cdee-97748b9ee299"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 parameters :  {'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'min_child_weight': 10, 'n_estimators': 300, 'objective': 'binary:logistic'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_clf = XGBClassifier(\n",
        "    gamma = 0,\n",
        "    learning_rate = 0.001,\n",
        "    max_depth = 3,\n",
        "    min_child_weight = 10,\n",
        "    n_estimators = 300,\n",
        "    objective = 'binary:logistic',\n",
        "    random_state = 777\n",
        ")\n",
        "\n",
        "\n",
        "pred = []\n",
        "for i in range(0,15) :\n",
        "\n",
        "  X_train = X.iloc[0:252+i, :].values\n",
        "  Y_train = Y.iloc[0:252+i].values\n",
        "\n",
        "  xgb_clf.fit(X_train,Y_train)\n",
        "\n",
        "  X_test = X.iloc[252+i,:].to_numpy()\n",
        "  pred.append( int(xgb_clf.predict(np.array(X_test).reshape((1,-1)))))"
      ],
      "metadata": {
        "id": "b8HD6bkTuoJV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQfwH9OmwQQ3",
        "outputId": "f00ae011-2ce3-4609-d648-d6096cf16b0b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "Y_test= Y.iloc[252:267]\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(np.array(Y_test), np.array(pred))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(np.array(Y_test), np.array(pred)).ravel()\n",
        "(tn, fp, fn, tp)\n",
        "\n",
        "# Accuracy\n",
        "accuracy =  (tp+tn)/(tp+tn+fp+fn)\n",
        "print('Accuracy : ', accuracy)\n",
        "\n",
        "# Precision\n",
        "precision = tp/(tp+fp)\n",
        "print('Precision : ', precision)\n",
        "\n",
        "# Recall\n",
        "recall = tp/(tp+fn)\n",
        "print('Recall : ', recall)\n",
        "\n",
        "# TPR\n",
        "tpr = tp / 8\n",
        "print('TPR : ', tpr)\n",
        "\n",
        "# FPR\n",
        "fpr = tn / 4\n",
        "print('FPR : ' , fpr)\n",
        "\n",
        "print('roc auc value {}'.format(roc_auc_score(Y_test,pred)))\n",
        "\n",
        "print('training score : ',xgb_clf.score(X_train,Y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9PR05FF5oSm",
        "outputId": "7ac83179-a5ff-43b2-cc95-2bf83616a21a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.6666666666666666\n",
            "Precision :  0.8571428571428571\n",
            "Recall :  0.6\n",
            "TPR :  0.75\n",
            "FPR :  1.0\n",
            "roc auc value 0.7000000000000002\n",
            "training score :  0.7368421052631579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_clf.fit(X_train, Y_train)\n",
        " \n",
        "visualizer = ROCAUC(xgb_clf, classes=[0, 1], micro=False, macro=False, per_class=False)\n",
        "visualizer.fit(X_train, Y_train)\n",
        "visualizer.score(X_train, Y_train)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "8IOZ2xaLSLF7",
        "outputId": "3e3d9b74-8359-4750-a5e2-55445123556f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-993c722a8fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvisualizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mROCAUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmicro\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmacro\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IBrAK64JUfnn",
        "outputId": "342e4bd1-87c0-429c-c7b3-64f8507250e8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           RPI    INDPRO   CUMFNS    HWI  CLF16OV  UEMPMEAN  CLAIMSx  \\\n",
              "0    10861.073   91.7942  80.7915   5386   142267      13.1   288400   \n",
              "1    10906.015   92.1272  80.6848   5484   142456      12.6   293750   \n",
              "2    10936.525   92.4733  80.8565   5390   142434      12.7   274750   \n",
              "3    10996.136   93.0619  81.0452   5424   142751      12.4   271600   \n",
              "4    11035.828   93.3427  80.7350   5069   142388      12.6   282250   \n",
              "..         ...       ...      ...    ...      ...       ...      ...   \n",
              "262  17801.835  101.9977  77.1881  10922   162126      29.1   257000   \n",
              "263  17791.488  101.7015  77.1177  11448   162294      28.6   221750   \n",
              "264  17711.363  102.5596  77.0128  11283   163687      24.6   227600   \n",
              "265  17727.726  103.5845  77.9996  11344   163991      26.6   195000   \n",
              "266  17666.265  104.4741  78.6364  11549   164409      24.2   178000   \n",
              "\n",
              "     CES1021000001  USCONS  MANEMP  ...     M2SL     REALLN   DTCTHFNM  TB3MS  \\\n",
              "0            511.3    6752   17284  ...   4666.2  1480.9395  421056.34   5.32   \n",
              "1            512.9    6730   17285  ...   4679.4  1491.6687  422437.48   5.55   \n",
              "2            512.8    6811   17302  ...   4710.2  1517.7228  423323.75   5.69   \n",
              "3            516.7    6794   17298  ...   4766.1  1541.1524  427912.64   5.66   \n",
              "4            519.7    6770   17279  ...   4753.9  1565.0958  432485.03   5.79   \n",
              "..             ...     ...     ...  ...      ...        ...        ...    ...   \n",
              "262          536.9    7502   12514  ...  21343.2  4761.9090  754662.69   0.05   \n",
              "263          545.3    7546   12555  ...  21483.2  4787.7529  753781.25   0.06   \n",
              "264          545.5    7552   12581  ...  21659.2  4804.5980  751635.23   0.15   \n",
              "265          554.7    7606   12631  ...  21750.3  4830.7663  753730.65   0.33   \n",
              "266          558.4    7626   12674  ...  21809.2  4864.9312  747716.57   0.44   \n",
              "\n",
              "     GS10   AAA  TWEXAFEGSMTHx  WPSFD49207  OILPRICEx  VIXCLSx  \n",
              "0    6.66  7.78     113.861710     135.200      27.18  24.8430  \n",
              "1    6.52  7.68     116.518147     136.600      29.35  25.4560  \n",
              "2    6.26  7.68     116.954713     137.300      29.89  24.7678  \n",
              "3    5.99  7.64     117.776366     136.900      25.74  29.8331  \n",
              "4    6.44  7.99     121.439543     137.000      28.78  29.4290  \n",
              "..    ...   ...            ...         ...        ...      ...  \n",
              "262  1.56  2.62     107.028400     231.921      79.15  19.1586  \n",
              "263  1.47  2.65     108.201700     232.047      71.71  21.2985  \n",
              "264  1.76  2.93     107.631800     235.764      83.22  22.9143  \n",
              "265  1.93  3.25     107.826000     241.677      91.64  26.1429  \n",
              "266  2.13  3.43     109.690500     246.637     108.50  26.9368  \n",
              "\n",
              "[267 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e87fb2f-cefe-46f7-a2ae-fad368956f29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RPI</th>\n",
              "      <th>INDPRO</th>\n",
              "      <th>CUMFNS</th>\n",
              "      <th>HWI</th>\n",
              "      <th>CLF16OV</th>\n",
              "      <th>UEMPMEAN</th>\n",
              "      <th>CLAIMSx</th>\n",
              "      <th>CES1021000001</th>\n",
              "      <th>USCONS</th>\n",
              "      <th>MANEMP</th>\n",
              "      <th>...</th>\n",
              "      <th>M2SL</th>\n",
              "      <th>REALLN</th>\n",
              "      <th>DTCTHFNM</th>\n",
              "      <th>TB3MS</th>\n",
              "      <th>GS10</th>\n",
              "      <th>AAA</th>\n",
              "      <th>TWEXAFEGSMTHx</th>\n",
              "      <th>WPSFD49207</th>\n",
              "      <th>OILPRICEx</th>\n",
              "      <th>VIXCLSx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10861.073</td>\n",
              "      <td>91.7942</td>\n",
              "      <td>80.7915</td>\n",
              "      <td>5386</td>\n",
              "      <td>142267</td>\n",
              "      <td>13.1</td>\n",
              "      <td>288400</td>\n",
              "      <td>511.3</td>\n",
              "      <td>6752</td>\n",
              "      <td>17284</td>\n",
              "      <td>...</td>\n",
              "      <td>4666.2</td>\n",
              "      <td>1480.9395</td>\n",
              "      <td>421056.34</td>\n",
              "      <td>5.32</td>\n",
              "      <td>6.66</td>\n",
              "      <td>7.78</td>\n",
              "      <td>113.861710</td>\n",
              "      <td>135.200</td>\n",
              "      <td>27.18</td>\n",
              "      <td>24.8430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10906.015</td>\n",
              "      <td>92.1272</td>\n",
              "      <td>80.6848</td>\n",
              "      <td>5484</td>\n",
              "      <td>142456</td>\n",
              "      <td>12.6</td>\n",
              "      <td>293750</td>\n",
              "      <td>512.9</td>\n",
              "      <td>6730</td>\n",
              "      <td>17285</td>\n",
              "      <td>...</td>\n",
              "      <td>4679.4</td>\n",
              "      <td>1491.6687</td>\n",
              "      <td>422437.48</td>\n",
              "      <td>5.55</td>\n",
              "      <td>6.52</td>\n",
              "      <td>7.68</td>\n",
              "      <td>116.518147</td>\n",
              "      <td>136.600</td>\n",
              "      <td>29.35</td>\n",
              "      <td>25.4560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10936.525</td>\n",
              "      <td>92.4733</td>\n",
              "      <td>80.8565</td>\n",
              "      <td>5390</td>\n",
              "      <td>142434</td>\n",
              "      <td>12.7</td>\n",
              "      <td>274750</td>\n",
              "      <td>512.8</td>\n",
              "      <td>6811</td>\n",
              "      <td>17302</td>\n",
              "      <td>...</td>\n",
              "      <td>4710.2</td>\n",
              "      <td>1517.7228</td>\n",
              "      <td>423323.75</td>\n",
              "      <td>5.69</td>\n",
              "      <td>6.26</td>\n",
              "      <td>7.68</td>\n",
              "      <td>116.954713</td>\n",
              "      <td>137.300</td>\n",
              "      <td>29.89</td>\n",
              "      <td>24.7678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10996.136</td>\n",
              "      <td>93.0619</td>\n",
              "      <td>81.0452</td>\n",
              "      <td>5424</td>\n",
              "      <td>142751</td>\n",
              "      <td>12.4</td>\n",
              "      <td>271600</td>\n",
              "      <td>516.7</td>\n",
              "      <td>6794</td>\n",
              "      <td>17298</td>\n",
              "      <td>...</td>\n",
              "      <td>4766.1</td>\n",
              "      <td>1541.1524</td>\n",
              "      <td>427912.64</td>\n",
              "      <td>5.66</td>\n",
              "      <td>5.99</td>\n",
              "      <td>7.64</td>\n",
              "      <td>117.776366</td>\n",
              "      <td>136.900</td>\n",
              "      <td>25.74</td>\n",
              "      <td>29.8331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11035.828</td>\n",
              "      <td>93.3427</td>\n",
              "      <td>80.7350</td>\n",
              "      <td>5069</td>\n",
              "      <td>142388</td>\n",
              "      <td>12.6</td>\n",
              "      <td>282250</td>\n",
              "      <td>519.7</td>\n",
              "      <td>6770</td>\n",
              "      <td>17279</td>\n",
              "      <td>...</td>\n",
              "      <td>4753.9</td>\n",
              "      <td>1565.0958</td>\n",
              "      <td>432485.03</td>\n",
              "      <td>5.79</td>\n",
              "      <td>6.44</td>\n",
              "      <td>7.99</td>\n",
              "      <td>121.439543</td>\n",
              "      <td>137.000</td>\n",
              "      <td>28.78</td>\n",
              "      <td>29.4290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>17801.835</td>\n",
              "      <td>101.9977</td>\n",
              "      <td>77.1881</td>\n",
              "      <td>10922</td>\n",
              "      <td>162126</td>\n",
              "      <td>29.1</td>\n",
              "      <td>257000</td>\n",
              "      <td>536.9</td>\n",
              "      <td>7502</td>\n",
              "      <td>12514</td>\n",
              "      <td>...</td>\n",
              "      <td>21343.2</td>\n",
              "      <td>4761.9090</td>\n",
              "      <td>754662.69</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1.56</td>\n",
              "      <td>2.62</td>\n",
              "      <td>107.028400</td>\n",
              "      <td>231.921</td>\n",
              "      <td>79.15</td>\n",
              "      <td>19.1586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>17791.488</td>\n",
              "      <td>101.7015</td>\n",
              "      <td>77.1177</td>\n",
              "      <td>11448</td>\n",
              "      <td>162294</td>\n",
              "      <td>28.6</td>\n",
              "      <td>221750</td>\n",
              "      <td>545.3</td>\n",
              "      <td>7546</td>\n",
              "      <td>12555</td>\n",
              "      <td>...</td>\n",
              "      <td>21483.2</td>\n",
              "      <td>4787.7529</td>\n",
              "      <td>753781.25</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.47</td>\n",
              "      <td>2.65</td>\n",
              "      <td>108.201700</td>\n",
              "      <td>232.047</td>\n",
              "      <td>71.71</td>\n",
              "      <td>21.2985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>17711.363</td>\n",
              "      <td>102.5596</td>\n",
              "      <td>77.0128</td>\n",
              "      <td>11283</td>\n",
              "      <td>163687</td>\n",
              "      <td>24.6</td>\n",
              "      <td>227600</td>\n",
              "      <td>545.5</td>\n",
              "      <td>7552</td>\n",
              "      <td>12581</td>\n",
              "      <td>...</td>\n",
              "      <td>21659.2</td>\n",
              "      <td>4804.5980</td>\n",
              "      <td>751635.23</td>\n",
              "      <td>0.15</td>\n",
              "      <td>1.76</td>\n",
              "      <td>2.93</td>\n",
              "      <td>107.631800</td>\n",
              "      <td>235.764</td>\n",
              "      <td>83.22</td>\n",
              "      <td>22.9143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>17727.726</td>\n",
              "      <td>103.5845</td>\n",
              "      <td>77.9996</td>\n",
              "      <td>11344</td>\n",
              "      <td>163991</td>\n",
              "      <td>26.6</td>\n",
              "      <td>195000</td>\n",
              "      <td>554.7</td>\n",
              "      <td>7606</td>\n",
              "      <td>12631</td>\n",
              "      <td>...</td>\n",
              "      <td>21750.3</td>\n",
              "      <td>4830.7663</td>\n",
              "      <td>753730.65</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.93</td>\n",
              "      <td>3.25</td>\n",
              "      <td>107.826000</td>\n",
              "      <td>241.677</td>\n",
              "      <td>91.64</td>\n",
              "      <td>26.1429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>17666.265</td>\n",
              "      <td>104.4741</td>\n",
              "      <td>78.6364</td>\n",
              "      <td>11549</td>\n",
              "      <td>164409</td>\n",
              "      <td>24.2</td>\n",
              "      <td>178000</td>\n",
              "      <td>558.4</td>\n",
              "      <td>7626</td>\n",
              "      <td>12674</td>\n",
              "      <td>...</td>\n",
              "      <td>21809.2</td>\n",
              "      <td>4864.9312</td>\n",
              "      <td>747716.57</td>\n",
              "      <td>0.44</td>\n",
              "      <td>2.13</td>\n",
              "      <td>3.43</td>\n",
              "      <td>109.690500</td>\n",
              "      <td>246.637</td>\n",
              "      <td>108.50</td>\n",
              "      <td>26.9368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>267 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e87fb2f-cefe-46f7-a2ae-fad368956f29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e87fb2f-cefe-46f7-a2ae-fad368956f29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e87fb2f-cefe-46f7-a2ae-fad368956f29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM**"
      ],
      "metadata": {
        "id": "TL-VmDqe_Z5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "bWBLvz4J_Yzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    # Long Short Term Memory\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_length = seq_length\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "        \n",
        "        c_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "        \n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        \n",
        "        out = self.fc(h_out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "YksJztuJRqws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "\n",
        "X_sc = sc.fit_transform(X)\n",
        "\n",
        "X_sc_df = pd.DataFrame(X_sc, columns=X.columns)"
      ],
      "metadata": {
        "id": "uRj1V2xMRt6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # device\n",
        "print(f\"{device} is avaiable\")\n",
        "if torch.cuda.is_available():\n",
        "  print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5747HRquVBpK",
        "outputId": "edfd5d97-e426-49b8-fffb-ceb1c9ebb993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 is avaiable\n",
            "Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_data(x, sequence_length):\n",
        "  \n",
        "  x_seq = []\n",
        "  for i in range(len(x) - sequence_length):\n",
        "    x_seq.append(x[i: i+sequence_length])\n",
        "\n",
        "  x_seq = np.array(x_seq)\n",
        "  return torch.FloatTensor(x_seq).to(device)"
      ],
      "metadata": {
        "id": "IV3otO00eDBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 12"
      ],
      "metadata": {
        "id": "S_yoTXZWePNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_seq= seq_data(X_sc_df, sequence_length)"
      ],
      "metadata": {
        "id": "ZZ3DPySUTMOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_size = \n",
        "x_train_seq = x_seq[:252]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FF1ZEsVeomb",
        "outputId": "94860875-ef6e-4d2b-f6f9-3286e2aa0c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "253"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int(len(X) * 0.95)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "ApWi_uS-zZ7c",
        "outputId": "216d940c-bb69-4e5f-cddc-db2bbe54e278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9515741c2c38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_data(x, y, sequence_length):\n",
        "  \n",
        "  x_seq = []\n",
        "  y_seq = []\n",
        "  for i in range(len(x) - sequence_length):\n",
        "    x_seq.append(x[i: i+sequence_length])\n",
        "    y_seq.append(y[i+sequence_length])\n",
        "\n",
        "  x_seq = np.array(x_seq)\n",
        "  y_seq = np.array(y_seq)\n",
        "  return torch.FloatTensor(x_seq).to(device), torch.FloatTensor(y_seq).to(device).view([-1, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Ya5IEKPlYOz1",
        "outputId": "05ac0d01-0864-4bb7-fe44-b4ba0563d723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          RPI    INDPRO    CUMFNS       HWI   CLF16OV  UEMPMEAN   CLAIMSx  \\\n",
              "0    0.000000  0.380303  0.987460  0.592189  0.000000  0.176119  0.022435   \n",
              "1    0.005503  0.396983  0.982186  0.610590  0.008450  0.161194  0.023630   \n",
              "2    0.009238  0.414319  0.990673  0.592940  0.007467  0.164179  0.019384   \n",
              "3    0.016537  0.443802  1.000000  0.599324  0.021640  0.155224  0.018681   \n",
              "4    0.021397  0.457867  0.984667  0.532670  0.005410  0.161194  0.021060   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "247  0.813998  0.585581  0.568143  0.766617  0.824466  0.376119  0.164103   \n",
              "248  0.826179  0.571030  0.572018  0.800225  0.799696  0.420896  0.148316   \n",
              "249  0.820330  0.623299  0.626538  0.871573  0.830144  0.441791  0.135724   \n",
              "250  0.798810  0.649120  0.650067  0.865941  0.816954  0.486567  0.125859   \n",
              "251  0.804542  0.705446  0.673709  0.883590  0.822856  0.492537  0.144964   \n",
              "\n",
              "     CES1021000001    USCONS    MANEMP  ...      M2SL    REALLN  DTCTHFNM  \\\n",
              "0         0.037677  0.576338  0.993558  ...  0.000000  0.000000  0.000000   \n",
              "1         0.042210  0.566768  0.993728  ...  0.000913  0.003343  0.002902   \n",
              "2         0.041926  0.602001  0.996610  ...  0.003043  0.011462  0.004764   \n",
              "3         0.052975  0.594606  0.995932  ...  0.006909  0.018762  0.014406   \n",
              "4         0.061473  0.584167  0.992711  ...  0.006066  0.026223  0.024013   \n",
              "..             ...       ...       ...  ...       ...       ...       ...   \n",
              "247       0.055241  0.780774  0.106289  ...  0.946924  0.998379  0.642255   \n",
              "248       0.047592  0.789909  0.113918  ...  0.961988  0.996986  0.650682   \n",
              "249       0.032011  0.812527  0.118495  ...  0.973089  0.993445  0.649976   \n",
              "250       0.026629  0.820357  0.124428  ...  0.989280  0.989143  0.655645   \n",
              "251       0.026346  0.839495  0.130022  ...  1.000000  0.986757  0.656416   \n",
              "\n",
              "        TB3MS      GS10       AAA  TWEXAFEGSMTHx  WPSFD49207  OILPRICEx  \\\n",
              "0    0.862013  1.000000  0.964103       0.622851    0.000000   0.090561   \n",
              "1    0.899351  0.976821  0.947009       0.675911    0.019231   0.109048   \n",
              "2    0.922078  0.933775  0.947009       0.684630    0.028846   0.113648   \n",
              "3    0.917208  0.889073  0.940171       0.701042    0.023352   0.078293   \n",
              "4    0.938312  0.963576  1.000000       0.774210    0.024725   0.104192   \n",
              "..        ...       ...       ...            ...         ...        ...   \n",
              "247  0.014610  0.004967  0.018803       0.469930    0.923077   0.219714   \n",
              "248  0.016234  0.009934  0.029060       0.476609    0.929945   0.196626   \n",
              "249  0.014610  0.028146  0.035897       0.476166    0.946429   0.194667   \n",
              "250  0.012987  0.041391  0.027350       0.458235    0.949176   0.207787   \n",
              "251  0.012987  0.051325  0.020513       0.411321    0.972527   0.259584   \n",
              "\n",
              "      VIXCLSx  \n",
              "0    0.279174  \n",
              "1    0.290765  \n",
              "2    0.277752  \n",
              "3    0.373530  \n",
              "4    0.365889  \n",
              "..        ...  \n",
              "247  0.242040  \n",
              "248  0.331067  \n",
              "249  0.366025  \n",
              "250  0.270605  \n",
              "251  0.232652  \n",
              "\n",
              "[252 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b48216f6-e8bb-4be0-ba44-c60bc6b634d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RPI</th>\n",
              "      <th>INDPRO</th>\n",
              "      <th>CUMFNS</th>\n",
              "      <th>HWI</th>\n",
              "      <th>CLF16OV</th>\n",
              "      <th>UEMPMEAN</th>\n",
              "      <th>CLAIMSx</th>\n",
              "      <th>CES1021000001</th>\n",
              "      <th>USCONS</th>\n",
              "      <th>MANEMP</th>\n",
              "      <th>...</th>\n",
              "      <th>M2SL</th>\n",
              "      <th>REALLN</th>\n",
              "      <th>DTCTHFNM</th>\n",
              "      <th>TB3MS</th>\n",
              "      <th>GS10</th>\n",
              "      <th>AAA</th>\n",
              "      <th>TWEXAFEGSMTHx</th>\n",
              "      <th>WPSFD49207</th>\n",
              "      <th>OILPRICEx</th>\n",
              "      <th>VIXCLSx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380303</td>\n",
              "      <td>0.987460</td>\n",
              "      <td>0.592189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176119</td>\n",
              "      <td>0.022435</td>\n",
              "      <td>0.037677</td>\n",
              "      <td>0.576338</td>\n",
              "      <td>0.993558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.862013</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.964103</td>\n",
              "      <td>0.622851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090561</td>\n",
              "      <td>0.279174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005503</td>\n",
              "      <td>0.396983</td>\n",
              "      <td>0.982186</td>\n",
              "      <td>0.610590</td>\n",
              "      <td>0.008450</td>\n",
              "      <td>0.161194</td>\n",
              "      <td>0.023630</td>\n",
              "      <td>0.042210</td>\n",
              "      <td>0.566768</td>\n",
              "      <td>0.993728</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.003343</td>\n",
              "      <td>0.002902</td>\n",
              "      <td>0.899351</td>\n",
              "      <td>0.976821</td>\n",
              "      <td>0.947009</td>\n",
              "      <td>0.675911</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.109048</td>\n",
              "      <td>0.290765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.009238</td>\n",
              "      <td>0.414319</td>\n",
              "      <td>0.990673</td>\n",
              "      <td>0.592940</td>\n",
              "      <td>0.007467</td>\n",
              "      <td>0.164179</td>\n",
              "      <td>0.019384</td>\n",
              "      <td>0.041926</td>\n",
              "      <td>0.602001</td>\n",
              "      <td>0.996610</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003043</td>\n",
              "      <td>0.011462</td>\n",
              "      <td>0.004764</td>\n",
              "      <td>0.922078</td>\n",
              "      <td>0.933775</td>\n",
              "      <td>0.947009</td>\n",
              "      <td>0.684630</td>\n",
              "      <td>0.028846</td>\n",
              "      <td>0.113648</td>\n",
              "      <td>0.277752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.016537</td>\n",
              "      <td>0.443802</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.599324</td>\n",
              "      <td>0.021640</td>\n",
              "      <td>0.155224</td>\n",
              "      <td>0.018681</td>\n",
              "      <td>0.052975</td>\n",
              "      <td>0.594606</td>\n",
              "      <td>0.995932</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006909</td>\n",
              "      <td>0.018762</td>\n",
              "      <td>0.014406</td>\n",
              "      <td>0.917208</td>\n",
              "      <td>0.889073</td>\n",
              "      <td>0.940171</td>\n",
              "      <td>0.701042</td>\n",
              "      <td>0.023352</td>\n",
              "      <td>0.078293</td>\n",
              "      <td>0.373530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.021397</td>\n",
              "      <td>0.457867</td>\n",
              "      <td>0.984667</td>\n",
              "      <td>0.532670</td>\n",
              "      <td>0.005410</td>\n",
              "      <td>0.161194</td>\n",
              "      <td>0.021060</td>\n",
              "      <td>0.061473</td>\n",
              "      <td>0.584167</td>\n",
              "      <td>0.992711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006066</td>\n",
              "      <td>0.026223</td>\n",
              "      <td>0.024013</td>\n",
              "      <td>0.938312</td>\n",
              "      <td>0.963576</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.774210</td>\n",
              "      <td>0.024725</td>\n",
              "      <td>0.104192</td>\n",
              "      <td>0.365889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>0.813998</td>\n",
              "      <td>0.585581</td>\n",
              "      <td>0.568143</td>\n",
              "      <td>0.766617</td>\n",
              "      <td>0.824466</td>\n",
              "      <td>0.376119</td>\n",
              "      <td>0.164103</td>\n",
              "      <td>0.055241</td>\n",
              "      <td>0.780774</td>\n",
              "      <td>0.106289</td>\n",
              "      <td>...</td>\n",
              "      <td>0.946924</td>\n",
              "      <td>0.998379</td>\n",
              "      <td>0.642255</td>\n",
              "      <td>0.014610</td>\n",
              "      <td>0.004967</td>\n",
              "      <td>0.018803</td>\n",
              "      <td>0.469930</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.219714</td>\n",
              "      <td>0.242040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>0.826179</td>\n",
              "      <td>0.571030</td>\n",
              "      <td>0.572018</td>\n",
              "      <td>0.800225</td>\n",
              "      <td>0.799696</td>\n",
              "      <td>0.420896</td>\n",
              "      <td>0.148316</td>\n",
              "      <td>0.047592</td>\n",
              "      <td>0.789909</td>\n",
              "      <td>0.113918</td>\n",
              "      <td>...</td>\n",
              "      <td>0.961988</td>\n",
              "      <td>0.996986</td>\n",
              "      <td>0.650682</td>\n",
              "      <td>0.016234</td>\n",
              "      <td>0.009934</td>\n",
              "      <td>0.029060</td>\n",
              "      <td>0.476609</td>\n",
              "      <td>0.929945</td>\n",
              "      <td>0.196626</td>\n",
              "      <td>0.331067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>0.820330</td>\n",
              "      <td>0.623299</td>\n",
              "      <td>0.626538</td>\n",
              "      <td>0.871573</td>\n",
              "      <td>0.830144</td>\n",
              "      <td>0.441791</td>\n",
              "      <td>0.135724</td>\n",
              "      <td>0.032011</td>\n",
              "      <td>0.812527</td>\n",
              "      <td>0.118495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.973089</td>\n",
              "      <td>0.993445</td>\n",
              "      <td>0.649976</td>\n",
              "      <td>0.014610</td>\n",
              "      <td>0.028146</td>\n",
              "      <td>0.035897</td>\n",
              "      <td>0.476166</td>\n",
              "      <td>0.946429</td>\n",
              "      <td>0.194667</td>\n",
              "      <td>0.366025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>0.798810</td>\n",
              "      <td>0.649120</td>\n",
              "      <td>0.650067</td>\n",
              "      <td>0.865941</td>\n",
              "      <td>0.816954</td>\n",
              "      <td>0.486567</td>\n",
              "      <td>0.125859</td>\n",
              "      <td>0.026629</td>\n",
              "      <td>0.820357</td>\n",
              "      <td>0.124428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.989280</td>\n",
              "      <td>0.989143</td>\n",
              "      <td>0.655645</td>\n",
              "      <td>0.012987</td>\n",
              "      <td>0.041391</td>\n",
              "      <td>0.027350</td>\n",
              "      <td>0.458235</td>\n",
              "      <td>0.949176</td>\n",
              "      <td>0.207787</td>\n",
              "      <td>0.270605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>0.804542</td>\n",
              "      <td>0.705446</td>\n",
              "      <td>0.673709</td>\n",
              "      <td>0.883590</td>\n",
              "      <td>0.822856</td>\n",
              "      <td>0.492537</td>\n",
              "      <td>0.144964</td>\n",
              "      <td>0.026346</td>\n",
              "      <td>0.839495</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.986757</td>\n",
              "      <td>0.656416</td>\n",
              "      <td>0.012987</td>\n",
              "      <td>0.051325</td>\n",
              "      <td>0.020513</td>\n",
              "      <td>0.411321</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.259584</td>\n",
              "      <td>0.232652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>252 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b48216f6-e8bb-4be0-ba44-c60bc6b634d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b48216f6-e8bb-4be0-ba44-c60bc6b634d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b48216f6-e8bb-4be0-ba44-c60bc6b634d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    }
  ]
}